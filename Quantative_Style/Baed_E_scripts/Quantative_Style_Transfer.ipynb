{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Quantative_Style_Transfer.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"4wSqamelaQC_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609154701998,"user_tz":-540,"elapsed":24959,"user":{"displayName":"Nguyen Tuyen","photoUrl":"","userId":"02227545183480780476"}},"outputId":"c4a4df7d-5946-408a-e767-49fc1777f312"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i30KS_r-aazQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609154703960,"user_tz":-540,"elapsed":738,"user":{"displayName":"Nguyen Tuyen","photoUrl":"","userId":"02227545183480780476"}},"outputId":"1cde227c-c4cd-44f3-a8fa-c6d8a90a5199"},"source":["cd './drive/My Drive/AI VIET NAM/Tensorflow/Generatives'\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/AI VIET NAM/Tensorflow/Generatives\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JR-RHq_xaa-o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609155229927,"user_tz":-540,"elapsed":526402,"user":{"displayName":"Nguyen Tuyen","photoUrl":"","userId":"02227545183480780476"}},"outputId":"2ff0fdfd-12eb-4d37-b3fb-10942991f51d"},"source":["import time\n","import os\n","import sys\n","import tensorflow as tf\n","from PIL import Image\n","from collections import OrderedDict\n","from matplotlib.pyplot import imshow\n","import numpy as np\n","from scipy import interpolate\n","from scipy import misc\n","import glob\n","from shutil import copyfile\n","import imutils\n","from tensorflow.keras.applications import VGG19\n","import cv2\n","from tensorflow.keras.models import Model\n","\n","model_dir = os.getcwd() + '/Models/'\n","content_dir = './quantative_style/Baed_E_scripts/content/' \n","style_dir =  './quantative_style/Baed_E_scripts/50styles/'\n","Reference_dir = './quantative_style/Baed_E_scripts/content/'\n","source_dir = './NeuralStyleTransfer/outputs/'\n","style_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1', 'block5_conv1']\n","content_layers = ['block5_conv2'] \n","\n","#vgg definition that conveniently let's you grab the outputs from any layer\n","def vgg_layers(layer_names):\n","  vgg = VGG19(include_top=False, weights=\"imagenet\")\n","  vgg.trainable= False\n","  outputs = [vgg.get_layer(name).output for name in layer_names]\n","\n","  return Model([vgg.input], outputs)\n","    \n","    \n","    \n","# a function generate corvariant matrix and means with  input feature map\n","def cov_mean(input):\n","    b,h,w,c = input.shape\n","    F = tf.reshape(input,(b,-1,c))\n","    mean_ = tf.math.reduce_mean( F,axis=1, keepdims=True)\n","    mean = tf.concat(h*w*[mean_], axis=1)\n","    F = F-mean\n","    G = tf.matmul(tf.transpose(F, perm=[0,2,1]),F) \n","    G = tf.math.divide(G, h*w)\n","    return tf.squeeze(G,axis=0), tf.squeeze(mean_)\n","\n","\n","\n","    \n","# pre and post processing for images\n","#img_size = 512 \n","# prep = transforms.Compose([transforms.Scale(img_size),\n","#                            transforms.ToTensor(),\n","#                            transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), #turn to BGR\n","#                            transforms.Normalize(mean=[0.40760392, 0.45795686, 0.48501961], #subtract imagenet mean\n","#                                                 std=[1,1,1]),\n","#                            transforms.Lambda(lambda x: x.mul_(255)),\n","#                           ])\n","# postpa = transforms.Compose([transforms.Lambda(lambda x: x.mul_(1./255)),\n","#                            transforms.Normalize(mean=[-0.40760392, -0.45795686, -0.48501961], #add imagenet mean\n","#                                                 std=[1,1,1]),\n","#                            transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), #turn to RGB\n","#                            ])\n","# postpb = transforms.Compose([transforms.ToPILImage()])\n","\n","# def postp(tensor): # to clip results in the range [0,1]\n","#     t = postpa(tensor)\n","#     t[t>1] = 1    \n","#     t[t<0] = 0\n","#     img = postpb(t)\n","#     return img\n","\n","#get network\n","vgg = vgg_layers(style_layers)\n","# vgg.load_state_dict(torch.load(model_dir + 'vgg_conv.pth'))\n","# for param in vgg.parameters():\n","#     param.requires_grad = False\n","# if torch.cuda.is_available():\n","#     vgg.cuda()\n","\n","    \n","references=[]\n","references = glob.glob(Reference_dir+\"*.jpg\")  # generate a list of reference images                    \n","\n","Total_Covs=[0,0,0,0,0]\n","style_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1', 'block5_conv1'] \n","\n","for sample in references:    \n","\n","    image = cv2.imread(sample)\n","    image = cv2.resize(image, (512,336))\n","    image = image/255.\n","    image = tf.cast(image, dtype=tf.float32)\n","    image = tf.expand_dims(image, axis=0)\n","    image = image *255.0\n","    image = tf.keras.applications.vgg19.preprocess_input(image)\n","    Covs_Means = [cov_mean(A) for A in vgg(image)] # generate corvariant matrix and means for each layer\n","    Total_Covs= [x+y[0] for x,y in zip(Total_Covs,Covs_Means)] # summation of corvariant matrix of each layer over references\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80142336/80134624 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2iAfWOLiMBfH","executionInfo":{"status":"ok","timestamp":1609155229931,"user_tz":-540,"elapsed":523748,"user":{"displayName":"Nguyen Tuyen","photoUrl":"","userId":"02227545183480780476"}}},"source":["def prep(image):\n","    #image = cv2.imread(link)\n","    #image = cv2.resize(image, (512,336))\n","    image = image/255.\n","    image = tf.cast(image, dtype=tf.float32)\n","    image = tf.expand_dims(image, axis=0)\n","    image = image *255.0\n","    image = tf.keras.applications.vgg19.preprocess_input(image)\n","    return image"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"vwmdWU4Z5b8d","executionInfo":{"status":"ok","timestamp":1609155229932,"user_tz":-540,"elapsed":523028,"user":{"displayName":"Nguyen Tuyen","photoUrl":"","userId":"02227545183480780476"}}},"source":["a = tf.random.normal((1,64,64,256))\n","b = tf.random.normal((1,4,9))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcuVsXMOabBw","executionInfo":{"status":"ok","timestamp":1609155229933,"user_tz":-540,"elapsed":519973,"user":{"displayName":"Nguyen Tuyen","photoUrl":"","userId":"02227545183480780476"}}},"source":["c,d= cov_mean(a)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lk-NEdP9abGg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609155229935,"user_tz":-540,"elapsed":519404,"user":{"displayName":"Nguyen Tuyen","photoUrl":"","userId":"02227545183480780476"}},"outputId":"2c29b9a2-5226-4ab7-ec19-33f939c38c96"},"source":["c.shape, d.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([256, 256]), TensorShape([256]))"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"qISq0J_RabKq","executionInfo":{"status":"ok","timestamp":1609155245966,"user_tz":-540,"elapsed":682,"user":{"displayName":"Nguyen Tuyen","photoUrl":"","userId":"02227545183480780476"}}},"source":["# Take an average over references\n","\n","AVG_Covs = [x/len(references) for x in Total_Covs]\n","\n","def PCA(A):\n","        S,U,V = tf.linalg.svd(A)\n","        return U,S,V \n","# make a decomposition of each layer    \n","PCA_basis = [PCA(data) for data in AVG_Covs]\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"2NOyti5NREHs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609155247481,"user_tz":-540,"elapsed":650,"user":{"displayName":"Nguyen Tuyen","photoUrl":"","userId":"02227545183480780476"}},"outputId":"6b471186-ec16-4958-a80d-cd5823458a4e"},"source":["PCA_basis[0][2].shape"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 64])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"Q0cnUoQfabNl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609155397102,"user_tz":-540,"elapsed":116623,"user":{"displayName":"Nguyen Tuyen","photoUrl":"","userId":"02227545183480780476"}},"outputId":"a6253125-7c92-4723-a372-a9d990e9a6d0"},"source":["# Dimensions\n","Ks = [ 18,100,128,280,256]\n","\n","file1 = open('./quantative_style/Baed_E_scripts/input.txt', 'r') \n","file2= open('./quantative_style/Baed_E_scripts/EValuation3.txt', 'w')\n","columns = [\"Name\",\"E1\",\"E2\",\"E3\",\"E4\",\"E5\",\"\\n\"]\n","name = '\\t'.join(columns) \n","file2.write(name)\n","\n","\n","for line in file1.readlines()[:]:\n","    print(line)\n","    \n","    filename  = line[:-1] \n","    sp =line[:].split('_')\n","    style =int(sp[0][5:]) \n","    content = int(sp[1][7:])\n","    method = sp[2]\n","\n","    print(style,content,method,filename)\n"," \n","\n","    img_dirs = [style_dir, source_dir+str(method)+'/']\n","    img_names = ['styles - %s.jpg'%style, filename]\n","    print(img_dirs[0] + img_names[0])\n","    imgs = [cv2.imread(img_dirs[i] + name) for i,name in enumerate(img_names)]\n","    imgs_torch = [prep(img) for img in imgs]\n","  \n","    # if torch.cuda.is_available():\n","    #     imgs_torch = [Variable(img.unsqueeze(0).cuda()) for img in imgs_torch]\n","    # else:\n","    #     imgs_torch = [Variable(img.unsqueeze(0)) for img in imgs_torch]\n","    style_image, syn_image= imgs_torch\n","\n","\n","    style_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1', 'block5_conv1'] \n","    content_layers = ['block5_conv2']  \n","\n","    style_targets = [cov_mean(A) for A in vgg(style_image)]\n","    syn_results = [cov_mean(A) for A in vgg(syn_image)]\n","\n","\n","    def PCA_Proj(A,P,k):\n","        return tf.matmul(tf.matmul(tf.transpose(P[0][:,:k]),A[0]),P[2][:,:k]), tf.matmul( tf.expand_dims(A[1],axis=0), P[0][:,:k] ) \n","    \n","    PCA_targets = [PCA_Proj(data,P ,k) for data,P,k in zip(style_targets,PCA_basis,Ks)]\n","    PCA_syn_results = [PCA_Proj(data,P ,k) for data,P,k in zip(syn_results,PCA_basis,Ks)]  \n","    #print(PCA_targets)   \n","  \n","    def Det(A,B):\n","        S,_,_ = tf.linalg.svd(A)\n","        #print(S)\n","        S1,_,_ = tf.linalg.svd(B)\n","        #print(S1)\n","        temp = tf.math.log(S1/S)\n","        #print(temp)\n","        u=0\n","        for a in temp:\n","            u +=a\n","        return u\n","    \n","    LogDet_AoverB = [ Det(syn[0],tar[0]) for syn,tar,k in zip(PCA_syn_results,PCA_targets,Ks)]\n","    #print(LogDet_AoverB[1])\n","    KLs = []\n","\n","    KL_parts  = [ (tf.linalg.trace(tf.linalg.matmul( tf.linalg.inv(y[0]), x[0])).numpy(), tf.squeeze(tf.linalg.matmul( tf.linalg.matmul((y[1] -x[1]),  tf.linalg.inv(y[0])), tf.transpose((y[1]-x[1])) )).numpy() ,-k, logD.numpy()) for x,y,logD, k in zip(PCA_syn_results,PCA_targets,LogDet_AoverB,Ks)]\n","    print(KL_parts)\n","    KLs.append(np.sum(x) for x in KL_parts )  # np.sum(x) gives the 2 KL divergence\n","    #print(KLs[0])\n","    KL_array = np.array(KLs)\n","    #print(KL_array)\n","    Es = [ str(-np.log(x)+ np.log(2)) for x in KLs[0]] # E value is -log(KL)\n","    new = [str(filename)] + Es +[\"\\n\"]  \n"," \n","    name = '\\t'.join(new) \n","    file2.write(name)\n","file1.close()\n","file2.close()\n","\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["style1_content123057_gramMatrix_iteration100.png\n","\n","1 123057 gramMatrix style1_content123057_gramMatrix_iteration100.png\n","./quantative_style/Baed_E_scripts/50styles/styles - 1.jpg\n","[(46.001823, 2.5318742, -18, -11.128999), (313.31046, 13.299076, -100, -89.359085), (288.4136, 21.053715, -128, -74.73175), (499.66595, 20.720293, -280, -26.191702), (244.71643, 12.585899, -256, 227.72403)]\n","style1_content123057_gramMatrix_iteration1000.png\n","\n","1 123057 gramMatrix style1_content123057_gramMatrix_iteration1000.png\n","./quantative_style/Baed_E_scripts/50styles/styles - 1.jpg\n","[(27.550812, 0.80336714, -18, -4.819681), (165.61072, 1.4210098, -100, -40.246), (210.65968, 4.182801, -128, -50.044044), (473.85092, 18.452326, -280, -45.902676), (222.59152, 17.993666, -256, 307.63733)]\n","style1_content123057_Pearson_iteration100.png\n","\n","1 123057 Pearson style1_content123057_Pearson_iteration100.png\n","./quantative_style/Baed_E_scripts/50styles/styles - 1.jpg\n","[(62.688953, 3.8295662, -18, -16.591597), (367.67737, 36.345478, -100, -96.398766), (275.82806, 70.78562, -128, -48.536243), (508.2619, 157.9745, -280, 71.93812), (222.35255, 27.755106, -256, 398.0215)]\n","style1_content123057_Pearson_iteration1000.png\n","\n","1 123057 Pearson style1_content123057_Pearson_iteration1000.png\n","./quantative_style/Baed_E_scripts/50styles/styles - 1.jpg\n","[(19.502125, 0.2281613, -18, -0.4784913), (121.144196, 1.2738081, -100, -6.584784), (122.23734, 5.6373587, -128, 37.49454), (230.71121, 17.859632, -280, 237.55269), (199.64903, 30.392326, -256, 450.69046)]\n","style1_content123057_Covariance_iteration100.png\n","\n","1 123057 Covariance style1_content123057_Covariance_iteration100.png\n","./quantative_style/Baed_E_scripts/50styles/styles - 1.jpg\n","[(65.04662, 4.3938956, -18, -16.01476), (438.0709, 30.281849, -100, -119.25969), (344.2002, 41.01478, -128, -96.7391), (493.15753, 55.95762, -280, -28.774542), (223.07582, 17.936502, -256, 321.28326)]\n","style1_content123057_Covariance_iteration1000.png\n","\n","1 123057 Covariance style1_content123057_Covariance_iteration1000.png\n","./quantative_style/Baed_E_scripts/50styles/styles - 1.jpg\n","[(32.68859, 0.7364989, -18, -7.9397936), (199.42712, 3.325247, -100, -56.657597), (240.4773, 7.2166023, -128, -66.12158), (479.38782, 17.509335, -280, -57.28601), (214.643, 21.985111, -256, 350.60934)]\n","style1_content123057_CosineSimilarity_iteration100.png\n","\n","1 123057 CosineSimilarity style1_content123057_CosineSimilarity_iteration100.png\n","./quantative_style/Baed_E_scripts/50styles/styles - 1.jpg\n","[(65.37036, 4.6922827, -18, -8.190193), (445.94046, 60.004505, -100, -95.10869), (260.71188, 109.915726, -128, -27.07786), (460.6355, 223.46634, -280, 125.449646), (223.10797, 27.31731, -256, 396.72543)]\n","style1_content123057_CosineSimilarity_iteration1000.png\n","\n","1 123057 CosineSimilarity style1_content123057_CosineSimilarity_iteration1000.png\n","./quantative_style/Baed_E_scripts/50styles/styles - 1.jpg\n","[(45.077312, 4.991134, -18, -2.0289466), (306.2234, 29.5631, -100, -59.128834), (184.23172, 39.75115, -128, 12.886684), (281.0732, 52.57735, -280, 223.01772), (199.8, 30.19273, -256, 450.96686)]\n","style1_content123057_Euclidean_iteration100.png\n","\n","1 123057 Euclidean style1_content123057_Euclidean_iteration100.png\n","./quantative_style/Baed_E_scripts/50styles/styles - 1.jpg\n","[(33.23912, 1.4806525, -18, -5.202695), (205.65344, 13.9714775, -100, -48.634357), (203.02591, 23.607431, -128, -28.993088), (456.733, 52.88908, -280, 35.15928), (226.27618, 26.870596, -256, 383.02817)]\n","style1_content123057_Euclidean_iteration1000.png\n","\n","1 123057 Euclidean style1_content123057_Euclidean_iteration1000.png\n","./quantative_style/Baed_E_scripts/50styles/styles - 1.jpg\n","[(24.921976, 0.24211335, -18, -4.219794), (155.1738, 0.8352907, -100, -35.17651), (220.5238, 3.2816, -128, -52.582718), (515.86084, 11.49181, -280, -34.21243), (210.33252, 29.408056, -256, 416.907)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZkLz9W1FabQw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxh7SwItabEl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MbAfN0nRaa81"},"source":[""],"execution_count":null,"outputs":[]}]}